---
title: "Compute & Hardware Supply in Data Centers"
format: html
toc: true
toc-depth: 2
page-layout: article
---

At the heart of every data center are **physical machines**: servers, storage arrays, and networking hardware that do the actual computing. This guide examines the core components, vendors, trends, and architectural designs that power everything from cloud platforms to AI clusters.

---

## 4.1 üñ•Ô∏è The Core Hardware Stack

### A. Servers

The workhorses of the data center. Come in various form factors:
- **Rack-mounted (1U/2U):** Standard enterprise units
- **Blade servers:** High-density, modular compute nodes
- **Custom hyperscale nodes:** Stripped-down for cost/power efficiency

| Component        | Purpose                       |
|------------------|-------------------------------|
| CPU              | General-purpose compute       |
| RAM              | Fast volatile memory          |
| NIC (Network Interface Card) | Connectivity         |
| SSD/HDD          | Storage (local or attached)   |
| BMC/iLO/iDRAC     | Out-of-band management        |

### B. Storage Systems

- **DAS (Direct Attached Storage):** Local drives on each server
- **NAS (Network Attached):** Shared file storage over the network
- **SAN (Storage Area Network):** High-speed, block-level storage
- **Object Storage:** Used in cloud-native environments (e.g. S3-compatible)

---

## 4.2 üß± Rack Architecture & Deployment

### Rack Units (U)
- **1U = 1.75 inches (4.445 cm)**
- Common racks: 42U, 45U, 48U

### Layout Considerations
- **Power draw per rack** (typically 5‚Äì30kW)
- **Hot/cold aisle alignment**
- **Cable management** and airflow optimization
- **Smart PDUs** for monitoring and outlet control

---

## 4.3 üöÄ AI, HPC, and Accelerated Hardware

High-performance workloads are driving the adoption of **specialized compute**.

### A. GPUs
- Ideal for parallel workloads like ML, rendering, simulations.
- Vendors: NVIDIA (A100, H100), AMD (MI300), Intel (Gaudi)

### B. TPUs, NPUs, and ASICs
- Purpose-built chips for specific workloads (e.g. Google's TPU for AI inference).
- Enable significant energy savings per operation.

### C. FPGA-Based Acceleration
- Reconfigurable logic used in finance, edge, and networking.

> üß† *AI clusters often require 10‚Äì50kW per rack, dense liquid cooling, and extremely high bandwidth interconnects (400G+).*

---

## 4.4 üèóÔ∏è Hyperscale vs Enterprise vs Edge

| Deployment Type | Characteristics                           | Examples                        |
|------------------|--------------------------------------------|----------------------------------|
| Enterprise        | General-purpose, mixed workloads           | Corporate data centers          |
| Hyperscale        | Uniform compute at massive scale          | AWS, Azure, Google              |
| Edge              | Compact, rugged, and latency-sensitive    | Mobile base stations, factories |

### Hyperscale Specialization

- **Disaggregated architecture:** Storage, compute, and networking built independently
- **Custom ASICs and motherboards**
- **Minimal I/O ports, no superfluous hardware (e.g. no VGA)**

---

## 4.5 üîå Power, Cooling, and Physical Constraints

Hardware selection ties directly to the facility‚Äôs capabilities.

- **High-density servers** (>10kW/rack) often require **liquid cooling**
- **Redundant PSUs** with automatic failover
- **Front-to-back airflow** to align with cooling zones
- **Rail kits** and tool-less mounting for efficient service

---

## 4.6 üîÑ Hardware Lifecycle & Supply Chain

### A. Procurement & Vendors
- **OEMs:** Dell, HPE, Lenovo, Supermicro
- **ODMs:** Quanta, Wiwynn, Foxconn (build for hyperscalers)

### B. Lifecycle Stages
1. Design / Custom spec
2. Procurement and burn-in testing
3. Deployment and provisioning
4. Maintenance (firmware, hot-swaps)
5. Decommissioning and resale/recycling

### C. Logistics Considerations
- Lead times, customs, and just-in-time delivery
- Asset tagging and tracking
- Secure data destruction on retirement

---

## 4.7 üìà Emerging Trends in Data Center Hardware

### 1. Composable Infrastructure
- Dynamically assign compute, storage, and network resources like software.
- Powered by high-speed interconnects and software APIs.

### 2. Liquid Cooling at Scale
- Direct-to-chip or immersion cooling becoming standard for AI workloads.
- Reduces need for massive HVAC systems.

### 3. RISC-V and Open Hardware
- Custom CPUs and open platforms gaining ground in HPC and edge deployments.

### 4. Smart NICs / DPUs (Data Processing Units)
- Offload tasks like encryption, network routing, and telemetry.
- Frees up CPUs and reduces overhead.

---

## 4.8 üíº Business Opportunities in Hardware Supply

- **System integration** for edge or AI workloads
- **Custom rack and enclosure design**
- **Resale/refurbishment** of decommissioned gear (secondary market)
- **Firmware and management software development**
- **Specialty cooling solutions** for high-density racks
- **Hardware monitoring and analytics platforms**

---

## üìö Further Reading & Resources

- [Open Compute Project (OCP)](https://www.opencompute.org/)
- [NVIDIA Data Center Solutions](https://www.nvidia.com/en-us/data-center/)
- [Uptime Institute Hardware Best Practices](https://uptimeinstitute.com/)
- [Backblaze Drive Stats](https://www.backblaze.com/b2/hard-drive-test-data.html)
- [ASRock Rack and Supermicro Products](https://www.supermicro.com/)

---

‚úçÔ∏è *Part of the Data Center Ecosystem Series. Go back to the [main index](index.html) or move ahead to [Cloud & Managed Services](Cloud.html).*
